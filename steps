Perfect üíØ ‚Äî you‚Äôve written a nice Jenkins declarative pipeline that covers Checkout ‚Üí Install ‚Üí SonarQube ‚Üí Package ‚Üí Nexus ‚Üí DockerHub.
Let‚Äôs go step by step (like you‚Äôd explain in an interview or configure in real life). I‚Äôll break this into:

Pre-requisites (Jenkins setup + external tools)

Pipeline stage-by-stage explanation + configuration

Where Docker fits in and what you must configure

üîπ 1. Pre-requisites Before Running Pipeline
Jenkins Plugins Needed

Git Plugin ‚Üí for git step.

NodeJS Plugin ‚Üí for tools { nodejs 'NodeJS' }.

SonarQube Scanner Plugin ‚Üí for withSonarQubeEnv.

Credentials Binding Plugin ‚Üí for secrets (Sonar token, DockerHub, Nexus).

Nexus Artifact Uploader Plugin ‚Üí for uploading .tar.gz.

Docker Pipeline Plugin ‚Üí for Docker build & push.

Jenkins Global Tool Configuration

NodeJS installation ‚Üí Manage Jenkins ‚Üí Tools ‚Üí NodeJS installations ‚Üí Name it NodeJS.

SonarQube Scanner ‚Üí Manage Jenkins ‚Üí Tools ‚Üí SonarQube Scanner installations ‚Üí Name it SonarQubeScanner.

SonarQube Server ‚Üí Manage Jenkins ‚Üí System ‚Üí SonarQube servers ‚Üí Name it sonar (must match pipeline).

Jenkins Credentials Setup

sonar-scanner ‚Üí store SonarQube token as Secret Text.

nexus ‚Üí store Nexus username/password as Username with password.

dockerhub ‚Üí store DockerHub username/password as Username with password.

External Tools Setup

SonarQube server running ‚Üí accessible at $SONAR_HOST_URL.

Nexus server running at http://3.109.152.197:8081.

DockerHub account with repo rateshivakumar/zaltixschool.

üîπ 2. Pipeline Stage-by-Stage Explanation
Stage 1: Checkout Code
git branch: 'main',
    url: 'https://github.com/rateshivakumar/ZaltixSchool.git'


Pulls code from your GitHub repo (branch main).

Jenkins needs Git plugin and access to GitHub (public repo works without creds).

Stage 2: Install Dependencies
dir('backend') {
    sh 'npm install'
}


Moves into backend folder.

Installs dependencies from package.json.

Requires NodeJS tool configured (your tools { nodejs 'NodeJS' } automatically sets PATH).

Stage 3: SonarQube Analysis
withSonarQubeEnv('sonar') {
  withCredentials([string(credentialsId: 'sonar-scanner', variable: 'SONAR_TOKEN')]) {
    withEnv(["PATH+SONAR=${tool 'SonarQubeScanner'}/bin"]) {
      sh '''
        sonar-scanner \
          -Dsonar.projectKey=ZaltixSchool \
          -Dsonar.sources=backend \
          -Dsonar.host.url=$SONAR_HOST_URL \
          -Dsonar.login=$SONAR_TOKEN
      '''
    }
  }
}


Connects to SonarQube server configured in Jenkins as sonar.

Injects Sonar token securely.

Runs sonar-scanner to analyze backend code quality & security.

Stage 4: Package Node.js App
cd backend
tar -czf ZaltixSchool-1.0.0.tar.gz *
mv ZaltixSchool-1.0.0.tar.gz ../


Compresses backend app into .tar.gz.

Moves artifact to root workspace (Jenkins default).

Stage 5: Upload Artifact to Nexus
nexusArtifactUploader(
    artifacts: [[
        artifactId: 'ZaltixSchool',
        file: 'ZaltixSchool-1.0.0.tar.gz',
        type: 'tar.gz'
    ]],
    credentialsId: 'nexus',
    groupId: 'in.zaltix.school',
    nexusUrl: '3.109.152.197:8081',
    repository: 'nodejs',
    version: '1.0.0'
)


Uploads artifact to Nexus Repository (nodejs).

Credentials (nexus) are injected securely.

Now your packaged app is stored in Nexus like Maven/Gradle artifacts.

Stage 6: Build & Push Docker Image
docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') {
    def app = docker.build("rateshivakumar/zaltixschool:latest")
    app.push()
    app.push("1.0.0")
}


Builds a Docker image from Dockerfile in repo root (by default).

Pushes image to DockerHub under your account:

latest tag

1.0.0 version tag

üëâ Important: You must have a valid Dockerfile in your repo root (or specify path). Example for Node.js backend:

# Base Image
FROM node:18-alpine

# Set working directory
WORKDIR /app

# Copy package.json & install deps
COPY backend/package*.json ./
RUN npm install

# Copy source code
COPY backend/ .

# Expose port
EXPOSE 8080

# Start app
CMD ["npm", "start"]

üîπ 3. Jenkins Commands & How to Run

After saving pipeline:

Start Jenkins job ‚Üí Jenkins clones repo.

Install dependencies ‚Üí npm install.

Run SonarQube ‚Üí Code analysis pushed to SonarQube UI.

Package app ‚Üí Creates .tar.gz.

Upload to Nexus ‚Üí Artifact stored in http://3.109.152.197:8081/repository/nodejs/.

Build Docker image ‚Üí Builds Node.js backend Docker image.

Push Docker image ‚Üí Uploads to DockerHub (rateshivakumar/zaltixschool).

‚úÖ After successful run:

SonarQube Dashboard ‚Üí code quality report.

Nexus Repo ‚Üí .tar.gz artifact stored.

DockerHub Repo ‚Üí Node.js image (latest, 1.0.0).




   1) Kubernetes manifests (put these under k8s/)
00-namespace.yaml (optional but clean)
apiVersion: v1
kind: Namespace
metadata:
  name: zaltix

10-backend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: zaltix
  labels: { app: backend }
spec:
  replicas: 2
  selector:
    matchLabels: { app: backend }
  template:
    metadata:
      labels: { app: backend }
    spec:
      containers:
        - name: backend
          image: rateshivakumar/backend-app:1.0.0   # ‚Üê your backend image
          ports:
            - containerPort: 8080
          env:
            - name: NODE_ENV
              value: production
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: zaltix
spec:
  selector: { app: backend }
  ports:
    - port: 80
      targetPort: 8080
  type: ClusterIP

20-web.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-frontend
  namespace: zaltix
  labels: { app: web-frontend }
spec:
  replicas: 2
  selector:
    matchLabels: { app: web-frontend }
  template:
    metadata:
      labels: { app: web-frontend }
    spec:
      containers:
        - name: web
          image: rateshivakumar/web-app:1.0.0       # ‚Üê your web image
          ports:
            - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: web-frontend-service
  namespace: zaltix
spec:
  selector: { app: web-frontend }
  ports:
    - port: 80
      targetPort: 80
  type: ClusterIP        # Use Ingress (recommended). For NodePort swap to NodePort.

21-mobile.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mobile-frontend
  namespace: zaltix
  labels: { app: mobile-frontend }
spec:
  replicas: 2
  selector:
    matchLabels: { app: mobile-frontend }
  template:
    metadata:
      labels: { app: mobile-frontend }
    spec:
      containers:
        - name: mobile
          image: rateshivakumar/mobile-app:1.0.0    # ‚Üê your mobile image
          ports:
            - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: mobile-frontend-service
  namespace: zaltix
spec:
  selector: { app: mobile-frontend }
  ports:
    - port: 80
      targetPort: 80
  type: ClusterIP        # Use Ingress (recommended). For NodePort swap to NodePort.

90-ingress.yaml (single domain for all 3)

Requires an ingress controller (NGINX). If your backend expects paths without /api, enable rewrite (shown below).

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: zaltix-ingress
  namespace: zaltix
  annotations:
    # If your backend DOES NOT expect the /api prefix, enable regex & rewrite:
    # nginx.ingress.kubernetes.io/use-regex: "true"
    # nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  rules:
    - host: zaltix.example.com      # ‚Üê replace with your domain
      http:
        paths:
          - path: /web
            pathType: Prefix
            backend:
              service:
                name: web-frontend-service
                port:
                  number: 80
          - path: /mobile
            pathType: Prefix
            backend:
              service:
                name: mobile-frontend-service
                port:
                  number: 80
          # Option A: backend expects /api prefix ‚Üí no rewrite needed
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: backend-service
                port:
                  number: 80

          # Option B: backend root (/) with rewrite (uncomment annotations above + replace this block)
          # - path: /api(/|$)(.*)
          #   pathType: Prefix
          #   backend:
          #     service:
          #       name: backend-service
          #       port:
          #         number: 80


Prefer Ingress. If you really want NodePort instead, change both frontend services to:

spec:
  type: NodePort
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30001  # web (optional explicit)


and similarly for mobile (e.g., 30002). Then access via http://<node-ip>:nodePort.

2) Apply once (manually)
kubectl apply -f k8s/00-namespace.yaml
kubectl apply -f k8s/10-backend.yaml
kubectl apply -f k8s/20-web.yaml
kubectl apply -f k8s/21-mobile.yaml
kubectl apply -f k8s/90-ingress.yaml
kubectl get pods -n zaltix
kubectl get svc -n zaltix
kubectl get ingress -n zaltix


If you don‚Äôt have an ingress controller yet:

helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx --create-namespace


Point DNS zaltix.example.com to your ingress controller‚Äôs public IP.

3) Jenkins ‚Äì add build/push of web & mobile + deploy

A. Make sure you have:

DockerHub creds: dockerhub

(Optional) Kubeconfig credential: kubeconfig (Secret file)

kubectl installed on the Jenkins agent

B. Add stages (snippet you can merge at the end of your current pipeline):

environment {
  APP_VERSION     = "1.0.0"
  DOCKERHUB_USER  = "rateshivakumar"
}

stage('Build & Push Web Image') {
  steps {
    dir('frontend/web') {
      sh 'npm ci || npm install'
      sh 'npm run build'
    }
    script {
      docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') {
        sh """
          docker build -t ${DOCKERHUB_USER}/web-app:${APP_VERSION} frontend/web
          docker tag ${DOCKERHUB_USER}/web-app:${APP_VERSION} ${DOCKERHUB_USER}/web-app:latest
          docker push ${DOCKERHUB_USER}/web-app:${APP_VERSION}
          docker push ${DOCKERHUB_USER}/web-app:latest
        """
      }
    }
  }
}

stage('Build & Push Mobile Image') {
  steps {
    dir('frontend/mobile') {
      sh 'npm ci || npm install'
      sh 'npm run build'
    }
    script {
      docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') {
        sh """
          docker build -t ${DOCKERHUB_USER}/mobile-app:${APP_VERSION} frontend/mobile
          docker tag ${DOCKERHUB_USER}/mobile-app:${APP_VERSION} ${DOCKERHUB_USER}/mobile-app:latest
          docker push ${DOCKERHUB_USER}/mobile-app:${APP_VERSION}
          docker push ${DOCKERHUB_USER}/mobile-app:latest
        """
      }
    }
  }
}

stage('Build & Push Backend Image') {
  steps {
    script {
      docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') {
        sh """
          docker build -t ${DOCKERHUB_USER}/backend-app:${APP_VERSION} backend
          docker tag ${DOCKERHUB_USER}/backend-app:${APP_VERSION} ${DOCKERHUB_USER}/backend-app:latest
          docker push ${DOCKERHUB_USER}/backend-app:${APP_VERSION}
          docker push ${DOCKERHUB_USER}/backend-app:latest
        """
      }
    }
  }
}

stage('Deploy to Kubernetes') {
  steps {
    withCredentials([file(credentialsId: 'kubeconfig', variable: 'KUBECONFIG')]) {
      sh '''
        kubectl apply -f k8s/00-namespace.yaml
        kubectl apply -f k8s/10-backend.yaml
        kubectl apply -f k8s/20-web.yaml
        kubectl apply -f k8s/21-mobile.yaml
        kubectl apply -f k8s/90-ingress.yaml
        kubectl -n zaltix rollout status deploy/backend
        kubectl -n zaltix rollout status deploy/web-frontend
        kubectl -n zaltix rollout status deploy/mobile-frontend
      '''
    }
  }
}


If you want to auto-bump image tags each run, set APP_VERSION from a build param or Git commit SHA and update the YAMLs with sed before applying:

sh "sed -i 's/backend-app:1.0.0/backend-app:${APP_VERSION}/' k8s/10-backend.yaml"
sh "sed -i 's/web-app:1.0.0/web-app:${APP_VERSION}/' k8s/20-web.yaml"
sh "sed -i 's/mobile-app:1.0.0/mobile-app:${APP_VERSION}/' k8s/21-mobile.yaml"

How your frontends call backend

If you use Ingress: frontends can call /api/... (same host), avoiding CORS.

If you skip Ingress: set your frontend API_BASE_URL to http://backend-service.zaltix.svc.cluster.local (internal), or expose backend as NodePort and use http://<node-ip>:<port>.























   
   
   
   
      1) Kubernetes manifests (put these under k8s/)
00-namespace.yaml (optional but clean)
apiVersion: v1
kind: Namespace
metadata:
  name: zaltix

10-backend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
  namespace: zaltix
  labels: { app: backend }
spec:
  replicas: 2
  selector:
    matchLabels: { app: backend }
  template:
    metadata:
      labels: { app: backend }
    spec:
      containers:
        - name: backend
          image: rateshivakumar/backend-app:1.0.0   # ‚Üê your backend image
          ports:
            - containerPort: 8080
          env:
            - name: NODE_ENV
              value: production
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: zaltix
spec:
  selector: { app: backend }
  ports:
    - port: 80
      targetPort: 8080
  type: ClusterIP

20-web.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-frontend
  namespace: zaltix
  labels: { app: web-frontend }
spec:
  replicas: 2
  selector:
    matchLabels: { app: web-frontend }
  template:
    metadata:
      labels: { app: web-frontend }
    spec:
      containers:
        - name: web
          image: rateshivakumar/web-app:1.0.0       # ‚Üê your web image
          ports:
            - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: web-frontend-service
  namespace: zaltix
spec:
  selector: { app: web-frontend }
  ports:
    - port: 80
      targetPort: 80
  type: ClusterIP        # Use Ingress (recommended). For NodePort swap to NodePort.

21-mobile.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mobile-frontend
  namespace: zaltix
  labels: { app: mobile-frontend }
spec:
  replicas: 2
  selector:
    matchLabels: { app: mobile-frontend }
  template:
    metadata:
      labels: { app: mobile-frontend }
    spec:
      containers:
        - name: mobile
          image: rateshivakumar/mobile-app:1.0.0    # ‚Üê your mobile image
          ports:
            - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: mobile-frontend-service
  namespace: zaltix
spec:
  selector: { app: mobile-frontend }
  ports:
    - port: 80
      targetPort: 80
  type: ClusterIP        # Use Ingress (recommended). For NodePort swap to NodePort.

90-ingress.yaml (single domain for all 3)

Requires an ingress controller (NGINX). If your backend expects paths without /api, enable rewrite (shown below).

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: zaltix-ingress
  namespace: zaltix
  annotations:
    # If your backend DOES NOT expect the /api prefix, enable regex & rewrite:
    # nginx.ingress.kubernetes.io/use-regex: "true"
    # nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  rules:
    - host: zaltix.example.com      # ‚Üê replace with your domain
      http:
        paths:
          - path: /web
            pathType: Prefix
            backend:
              service:
                name: web-frontend-service
                port:
                  number: 80
          - path: /mobile
            pathType: Prefix
            backend:
              service:
                name: mobile-frontend-service
                port:
                  number: 80
          # Option A: backend expects /api prefix ‚Üí no rewrite needed
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: backend-service
                port:
                  number: 80

          # Option B: backend root (/) with rewrite (uncomment annotations above + replace this block)
          # - path: /api(/|$)(.*)
          #   pathType: Prefix
          #   backend:
          #     service:
          #       name: backend-service
          #       port:
          #         number: 80


Prefer Ingress. If you really want NodePort instead, change both frontend services to:

spec:
  type: NodePort
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30001  # web (optional explicit)


and similarly for mobile (e.g., 30002). Then access via http://<node-ip>:nodePort.

2) Apply once (manually)
kubectl apply -f k8s/00-namespace.yaml
kubectl apply -f k8s/10-backend.yaml
kubectl apply -f k8s/20-web.yaml
kubectl apply -f k8s/21-mobile.yaml
kubectl apply -f k8s/90-ingress.yaml
kubectl get pods -n zaltix
kubectl get svc -n zaltix
kubectl get ingress -n zaltix


If you don‚Äôt have an ingress controller yet:

helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install ingress-nginx ingress-nginx/ingress-nginx -n ingress-nginx --create-namespace


Point DNS zaltix.example.com to your ingress controller‚Äôs public IP.

3) Jenkins ‚Äì add build/push of web & mobile + deploy

A. Make sure you have:

DockerHub creds: dockerhub

(Optional) Kubeconfig credential: kubeconfig (Secret file)

kubectl installed on the Jenkins agent

B. Add stages (snippet you can merge at the end of your current pipeline):

environment {
  APP_VERSION     = "1.0.0"
  DOCKERHUB_USER  = "rateshivakumar"
}

stage('Build & Push Web Image') {
  steps {
    dir('frontend/web') {
      sh 'npm ci || npm install'
      sh 'npm run build'
    }
    script {
      docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') {
        sh """
          docker build -t ${DOCKERHUB_USER}/web-app:${APP_VERSION} frontend/web
          docker tag ${DOCKERHUB_USER}/web-app:${APP_VERSION} ${DOCKERHUB_USER}/web-app:latest
          docker push ${DOCKERHUB_USER}/web-app:${APP_VERSION}
          docker push ${DOCKERHUB_USER}/web-app:latest
        """
      }
    }
  }
}

stage('Build & Push Mobile Image') {
  steps {
    dir('frontend/mobile') {
      sh 'npm ci || npm install'
      sh 'npm run build'
    }
    script {
      docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') {
        sh """
          docker build -t ${DOCKERHUB_USER}/mobile-app:${APP_VERSION} frontend/mobile
          docker tag ${DOCKERHUB_USER}/mobile-app:${APP_VERSION} ${DOCKERHUB_USER}/mobile-app:latest
          docker push ${DOCKERHUB_USER}/mobile-app:${APP_VERSION}
          docker push ${DOCKERHUB_USER}/mobile-app:latest
        """
      }
    }
  }
}

stage('Build & Push Backend Image') {
  steps {
    script {
      docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') {
        sh """
          docker build -t ${DOCKERHUB_USER}/backend-app:${APP_VERSION} backend
          docker tag ${DOCKERHUB_USER}/backend-app:${APP_VERSION} ${DOCKERHUB_USER}/backend-app:latest
          docker push ${DOCKERHUB_USER}/backend-app:${APP_VERSION}
          docker push ${DOCKERHUB_USER}/backend-app:latest
        """
      }
    }
  }
}

stage('Deploy to Kubernetes') {
  steps {
    withCredentials([file(credentialsId: 'kubeconfig', variable: 'KUBECONFIG')]) {
      sh '''
        kubectl apply -f k8s/00-namespace.yaml
        kubectl apply -f k8s/10-backend.yaml
        kubectl apply -f k8s/20-web.yaml
        kubectl apply -f k8s/21-mobile.yaml
        kubectl apply -f k8s/90-ingress.yaml
        kubectl -n zaltix rollout status deploy/backend
        kubectl -n zaltix rollout status deploy/web-frontend
        kubectl -n zaltix rollout status deploy/mobile-frontend
      '''
    }
  }
}


If you want to auto-bump image tags each run, set APP_VERSION from a build param or Git commit SHA and update the YAMLs with sed before applying:

sh "sed -i 's/backend-app:1.0.0/backend-app:${APP_VERSION}/' k8s/10-backend.yaml"
sh "sed -i 's/web-app:1.0.0/web-app:${APP_VERSION}/' k8s/20-web.yaml"
sh "sed -i 's/mobile-app:1.0.0/mobile-app:${APP_VERSION}/' k8s/21-mobile.yaml"

How your frontends call backend

If you use Ingress: frontends can call /api/... (same host), avoiding CORS.

If you skip Ingress: set your frontend API_BASE_URL to http://backend-service.zaltix.svc.cluster.local (internal), or expose backend as NodePort and use http://<node-ip>:<port>.
